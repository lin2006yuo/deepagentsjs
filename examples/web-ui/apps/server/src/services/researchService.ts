import * as path from "path";
import * as fs from "fs";
import { fileURLToPath } from "url";
import type { ResearchStreamChunk, ResearchSession } from "@deepagents/shared";
import { generateId } from "@deepagents/shared";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Data paths
const SESSIONS_PATH = path.join(__dirname, "../../data/sessions");
const KNOWLEDGE_PATH = path.join(__dirname, "../../data/knowledge");

// Ensure directories exist
if (!fs.existsSync(SESSIONS_PATH)) {
  fs.mkdirSync(SESSIONS_PATH, { recursive: true });
}

interface StreamResearchOptions {
  question: string;
  sessionId?: string;
  knowledgeBase?: string[];
  onChunk: (chunk: ResearchStreamChunk) => void;
  abortSignal: AbortSignal;
}

// Research phases
const PHASES = [
  { id: "initialization", name: "åˆå§‹åŒ–", icon: "ğŸš€" },
  { id: "knowledge_search", name: "çŸ¥è¯†æœç´¢", icon: "ğŸ”" },
  { id: "analysis", name: "æ·±åº¦åˆ†æ", icon: "ğŸ§ " },
  { id: "report_generation", name: "æŠ¥å‘Šç”Ÿæˆ", icon: "ğŸ“" },
  { id: "completed", name: "å®Œæˆ", icon: "âœ…" },
] as const;

// Save session to disk
function saveSession(session: ResearchSession): void {
  const filePath = path.join(SESSIONS_PATH, `${session.id}.json`);
  fs.writeFileSync(filePath, JSON.stringify(session, null, 2), "utf-8");
}

// Load session from disk
function loadSession(sessionId: string): ResearchSession | null {
  const filePath = path.join(SESSIONS_PATH, `${sessionId}.json`);
  if (!fs.existsSync(filePath)) {
    return null;
  }
  try {
    return JSON.parse(fs.readFileSync(filePath, "utf-8"));
  } catch {
    return null;
  }
}

// Simulate research process
export async function streamResearch(options: StreamResearchOptions): Promise<void> {
  const { question, sessionId: existingSessionId, onChunk, abortSignal } = options;

  // Create or load session
  const sessionId = existingSessionId || generateId();
  let session = loadSession(sessionId);

  if (!session) {
    session = {
      id: sessionId,
      question,
      status: "running",
      createdAt: Date.now(),
      updatedAt: Date.now(),
      todos: [],
    };
  } else {
    session.status = "running";
    session.updatedAt = Date.now();
  }

  saveSession(session);

  // Send initial phase
  onChunk({ type: "phase", phase: PHASES[0].id, phaseName: PHASES[0].name, phaseIcon: PHASES[0].icon });

  // Phase 1: Initialization
  await delay(300);
  if (abortSignal.aborted) throw new Error("AbortError");
  onChunk({ type: "thinking", content: "æ­£åœ¨åˆ†æç ”ç©¶é—®é¢˜..." });

  await delay(300);
  if (abortSignal.aborted) throw new Error("AbortError");
  onChunk({ type: "thinking", content: `ç ”ç©¶ä¸»é¢˜: ${question}` });

  // Phase 2: Knowledge Search
  onChunk({ type: "phase", phase: PHASES[1].id, phaseName: PHASES[1].name, phaseIcon: PHASES[1].icon });

  await delay(400);
  if (abortSignal.aborted) throw new Error("AbortError");
  onChunk({ type: "tool_call", toolName: "knowledge_base_search", toolData: { query: question } });

  await delay(400);
  if (abortSignal.aborted) throw new Error("AbortError");
  onChunk({ type: "thinking", content: "æ­£åœ¨æœç´¢æœ¬åœ°çŸ¥è¯†åº“..." });

  // Check knowledge base files
  let knowledgeFiles: string[] = [];
  if (fs.existsSync(KNOWLEDGE_PATH)) {
    knowledgeFiles = fs.readdirSync(KNOWLEDGE_PATH).filter((f) => f.endsWith(".md"));
  }

  if (knowledgeFiles.length > 0) {
    await delay(300);
    if (abortSignal.aborted) throw new Error("AbortError");
    onChunk({ type: "thinking", content: `å‘ç° ${knowledgeFiles.length} ä¸ªçŸ¥è¯†åº“æ–‡æ¡£` });

    for (const file of knowledgeFiles.slice(0, 3)) {
      await delay(300);
      if (abortSignal.aborted) throw new Error("AbortError");
      onChunk({ type: "tool_call", toolName: "read_file", toolData: { file } });
    }
  }

  // Phase 3: Analysis
  onChunk({ type: "phase", phase: PHASES[2].id, phaseName: PHASES[2].name, phaseIcon: PHASES[2].icon });

  await delay(400);
  if (abortSignal.aborted) throw new Error("AbortError");
  onChunk({ type: "subagent", content: "å¯åŠ¨ç ”ç©¶å­ä»£ç†...", subAgentName: "analyzer" });

  // Add todos
  const todos = [
    { content: "æœç´¢çŸ¥è¯†åº“æ–‡æ¡£", status: "completed" },
    { content: "åˆ†æç ”ç©¶ä¸»é¢˜", status: "in_progress" },
    { content: "ç”Ÿæˆç ”ç©¶æŠ¥å‘Š", status: "pending" },
  ];

  for (const todo of todos) {
    await delay(200);
    if (abortSignal.aborted) throw new Error("AbortError");
    onChunk({ type: "todo", content: `ä»»åŠ¡: ${todo.content} [${todo.status}]` });
  }

  // Phase 4: Report Generation
  onChunk({ type: "phase", phase: PHASES[3].id, phaseName: PHASES[3].name, phaseIcon: PHASES[3].icon });

  await delay(500);
  if (abortSignal.aborted) throw new Error("AbortError");

  // Generate mock report
  const mockReport = `# ç ”ç©¶æŠ¥å‘Š: ${question}

## æ¦‚è¿°

æœ¬æŠ¥å‘ŠåŸºäºæœ¬åœ°çŸ¥è¯†åº“å¯¹ "${question}" è¿›è¡Œäº†æ·±å…¥ç ”ç©¶ã€‚

## ç ”ç©¶å‘ç°

### 1. æ ¸å¿ƒæ¦‚å¿µ

æ ¹æ®çŸ¥è¯†åº“æ–‡æ¡£ï¼Œæˆ‘ä»¬å‘ç°ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š

- **LangGraph**: ä¸€ä¸ªç”¨äºæ„å»ºå¤æ‚ AI ä»£ç†å·¥ä½œæµçš„æ¡†æ¶
- **Deep Agents**: åŸºäº LangGraph çš„é«˜çº§ä»£ç†åº“
- **AI Agent æ¨¡å¼**: åŒ…æ‹¬ ReActã€Plan-and-Execute ç­‰è®¾è®¡æ¨¡å¼

### 2. æŠ€æœ¯ç»†èŠ‚

#### LangGraph ç‰¹æ€§
- æ”¯æŒçŠ¶æ€ç®¡ç†
- å›¾ç»“æ„å·¥ä½œæµ
- äººæœºååŒ (HITL)

#### Deep Agents èƒ½åŠ›
- å­ä»£ç†ç³»ç»Ÿ
- æŠ€èƒ½ç®¡ç†
- è®°å¿†æŒä¹…åŒ–

## ç»“è®º

ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨ LangGraph å’Œ Deep Agents å¯ä»¥æ„å»ºå¼ºå¤§çš„ AI ä»£ç†ç³»ç»Ÿã€‚

## æ¥æº

- langgraph-intro.md
- deep-agents-guide.md
- ai-agent-patterns.md
`;

  onChunk({ type: "report", content: mockReport });

  // Phase 5: Completed
  onChunk({ type: "phase", phase: PHASES[4].id, phaseName: PHASES[4].name, phaseIcon: PHASES[4].icon });

  // Update session
  session.status = "completed";
  session.updatedAt = Date.now();
  session.report = mockReport;
  session.todos = todos;
  saveSession(session);

  // Send done
  onChunk({ type: "done" });
}

// Helper function for delays
function delay(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}
